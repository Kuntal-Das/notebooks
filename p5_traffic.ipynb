{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "p5-traffic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMhoE1Ga+Yir8jf1bCXMvH9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kuntal-Das/notebooks/blob/main/p5_traffic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2I19vHXJKth2"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "EPOCHS = 10\n",
        "IMG_WIDTH = 30\n",
        "IMG_HEIGHT = 30\n",
        "NUM_CATEGORIES = 43\n",
        "TEST_SIZE = 0.4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Nv3dOloH9IM"
      },
      "source": [
        "def main():\n",
        "\n",
        "    # Check command-line arguments\n",
        "    if len(sys.argv) not in [2, 3]:\n",
        "        sys.exit(\"Usage: python traffic.py data_directory [model.h5]\")\n",
        "\n",
        "    # Get image arrays and labels for all image files\n",
        "    images, labels = load_data(sys.argv[1])\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    labels = tf.keras.utils.to_categorical(labels)\n",
        "    x_train, x_test, y_train, y_test = train_test_split(\n",
        "        np.array(images), np.array(labels), test_size=TEST_SIZE\n",
        "    )\n",
        "\n",
        "    # Get a compiled neural network\n",
        "    model = get_model()\n",
        "\n",
        "    # Fit model on training data\n",
        "    model.fit(x_train, y_train, epochs=EPOCHS)\n",
        "\n",
        "    # Evaluate neural network performance\n",
        "    model.evaluate(x_test,  y_test, verbose=2)\n",
        "\n",
        "    # Save model to file\n",
        "    if len(sys.argv) == 3:\n",
        "        filename = sys.argv[2]\n",
        "        model.save(filename)\n",
        "        print(f\"Model saved to {filename}.\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKood0B5K7sf"
      },
      "source": [
        "def load_data(data_dir):\n",
        "    \"\"\"\n",
        "    Load image data from directory `data_dir`.\n",
        "\n",
        "    Assume `data_dir` has one directory named after each category, numbered\n",
        "    0 through NUM_CATEGORIES - 1. Inside each category directory will be some\n",
        "    number of image files.\n",
        "\n",
        "    Return tuple `(images, labels)`. `images` should be a list of all\n",
        "    of the images in the data directory, where each image is formatted as a\n",
        "    numpy ndarray with dimensions IMG_WIDTH x IMG_HEIGHT x 3. `labels` should\n",
        "    be a list of integer labels, representing the categories for each of the\n",
        "    corresponding `images`.\n",
        "    \"\"\"\n",
        "\n",
        "    images,labels = list(), list()\n",
        "\n",
        "    for category in range(0,NUM_CATEGORIES):\n",
        "        abs_dir_path = os.path.abspath(os.path.join(\"gtsrb\",f\"{category}\"))\n",
        "        imgs = os.listdir(abs_dir_path)\n",
        "        for img_str in imgs:\n",
        "            img_path = os.path.join(abs_dir_path,img_str)\n",
        "            img = cv2.imread(img_path, 1)\n",
        "            h, w = img.shape[:2]\n",
        "\n",
        "            if (h, w) == (IMG_HEIGHT, IMG_WIDTH):\n",
        "                images.append(img)\n",
        "            elif h*w > IMG_HEIGHT*IMG_WIDTH:\n",
        "                img = cv2.resize(img, (IMG_HEIGHT,IMG_WIDTH),interpolation=cv2.INTER_AREA)\n",
        "                images.append(img)\n",
        "            else:\n",
        "                img = cv2.resize(img, (IMG_HEIGHT,IMG_WIDTH))\n",
        "                images.append(img)\n",
        "                \n",
        "            labels.append(category)\n",
        "\n",
        "    return (images,labels)\n",
        "    # raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlC9lfbPKzHQ"
      },
      "source": [
        "def get_model():\n",
        "    \"\"\"\n",
        "    Returns a compiled convolutional neural network model. Assume that the\n",
        "    `input_shape` of the first layer is `(IMG_WIDTH, IMG_HEIGHT, 3)`.\n",
        "    The output layer should have `NUM_CATEGORIES` units, one for each category.\n",
        "    \"\"\"\n",
        "    \n",
        "    pass\n",
        "    # raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0ON7_uFK1e5"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}